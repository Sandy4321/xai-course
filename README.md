
# Intro to explainable machine learning

## Goal
Learn how to make your machine learning models explainable


## About this course
Machine learning is being built into many products and processes of our daily lives, yet decisions made by machines don't automatically come with an explanation. An explanation increases the trust in the decision and in the machine learning model. As the programmer of an algorithm you want to know whether you can trust the learned model. Did it learn generalizable features? Or are there some odd artifacts in the training data which the algorithm picked up? In this course you will learn different techniques to increase the interpretability of your machine learning model and to explain single predictions. This course focuses on model-agnostic techniques which can be applied to your current machine learning model whether it is a neural network, a random forest or a bayesian model.


## Course outline

1. Motivation: When do we need explainable machine learning models?
2. Types of explainability
3. Simple, interpretable models
  - Sparse linear models
  - Decision trees
4. Global model interpretability techniques
  - Partial dependency plots
  - Variable importance
  - Proxy models
5. Local, interpretable model-agnostic explanations (LIME)
  - Tabular data
  - Text data
  - Image data


## Prerequisites

- Basic knowledge in statistics and machine learning
- Experience in programming
